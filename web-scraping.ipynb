{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70ea72cc-f834-4dca-8e82-5010cdb1d351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV created: uci_scraped_links.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/datasets?search=heart+disease\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, headers=headers, timeout=10)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    dataset_list = []\n",
    "    # UCI now uses <a> tags with specific classes for dataset names\n",
    "    links = soup.find_all('a', class_='link-hover link-primary')\n",
    "    \n",
    "    for link in links[:10]:\n",
    "        title = link.get_text().strip()\n",
    "        href = \"https://archive.ics.uci.edu\" + link['href']\n",
    "        dataset_list.append({\"Dataset Name\": title, \"Link\": href})\n",
    "        print(f\"Found: {title} -> {href}\")\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(dataset_list)\n",
    "    df.to_csv(\"uci_scraped_links.csv\", index=False)\n",
    "    print(\"\\nCSV created: uci_scraped_links.csv\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Network error: {e}. Check your connection or try a different URL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9128076b-8db1-442c-b0a8-9a40e48e3a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved: govt_data.csv\n",
      "Successfully saved: medical_data.csv\n",
      "No specific heart attributes found at https://data.gov.in/keywords/heart\n",
      "\n",
      "--- Round 1 Data Collection Phase Complete ---\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define target sites and their output filenames\n",
    "targets = [\n",
    "    {\"url\": \"https://catalog.data.gov/dataset/?tags=heart-disease\", \"file\": \"govt_data.csv\"},\n",
    "    {\"url\": \"https://www.mayoclinic.org/diseases-conditions/heart-disease/symptoms-causes/syc-20353118\", \"file\": \"medical_data.csv\"},\n",
    "    {\"url\": \"https://data.gov.in/keywords/heart\", \"file\": \"research_data.csv\"}\n",
    "]\n",
    "\n",
    "# The 13 attributes from your heart.doc to look for\n",
    "attributes = [\n",
    "    'age', 'sex', 'chest pain', 'blood pressure', 'cholestoral', \n",
    "    'sugar', 'electrocardiographic', 'heart rate', 'angina', \n",
    "    'oldpeak', 'slope', 'vessels', 'thal'\n",
    "]\n",
    "\n",
    "def extract_and_save(target):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    try:\n",
    "        # Request with 10s timeout to bypass local DNS lags\n",
    "        response = requests.get(target[\"url\"], headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        extracted_data = []\n",
    "        # Searching through list items, table cells, and paragraphs\n",
    "        for tag in soup.find_all(['li', 'td', 'p']):\n",
    "            text = tag.get_text().strip().lower()\n",
    "            # If the text contains one of our 13 attributes, save it [cite: 99, 100, 101, 102]\n",
    "            if any(attr in text for attr in attributes):\n",
    "                extracted_data.append({\"Source\": target[\"url\"], \"Content\": text})\n",
    "        \n",
    "        # Convert the list of findings into a CSV\n",
    "        if extracted_data:\n",
    "            df = pd.DataFrame(extracted_data)\n",
    "            df.to_csv(target[\"file\"], index=False)\n",
    "            print(f\"Successfully saved: {target['file']}\")\n",
    "        else:\n",
    "            print(f\"No specific heart attributes found at {target['url']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape {target['url']}: {e}\")\n",
    "\n",
    "# Run the process one by one\n",
    "for t in targets:\n",
    "    extract_and_save(t)\n",
    "\n",
    "print(\"\\n--- Round 1 Data Collection Phase Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab0f909-b8ce-4bbc-b49c-7b20e61bf300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 529, 'name': 'Early Stage Diabetes Risk Prediction', 'repository_url': 'https://archive.ics.uci.edu/dataset/529/early+stage+diabetes+risk+prediction+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/529/data.csv', 'abstract': 'This dataset contains the sign and symptpom data of newly diabetic or would be diabetic patient. ', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 520, 'num_features': 16, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Gender'], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2020, 'last_updated': 'Mon Mar 04 2024', 'dataset_doi': '10.24432/C5VG8H', 'creators': [], 'intro_paper': {'ID': 397, 'type': 'NATIVE', 'title': 'Likelihood Prediction of Diabetes at Early Stage Using Data Mining Techniques', 'authors': 'M. M. F. Islam, Rahatara Ferdousi, Sadikur Rahman, Humayra Yasmin Bushra', 'venue': 'Computer Vision and Machine Intelligence in Medical Image Analysis', 'year': 2019, 'journal': None, 'DOI': '10.1007/978-981-13-8798-2_12', 'URL': 'https://www.semanticscholar.org/paper/9329dec57c5f13f195220ffa7077fd0029983f07', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This has been col-\\r\\nlected using direct questionnaires from the patients of Sylhet Diabetes\\r\\nHospital in Sylhet, Bangladesh and approved by a doctor.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Age 1.20-65\\t\\t\\r\\nSex 1. Male, 2.Female\\t\\t\\r\\nPolyuria 1.Yes, 2.No.\\t\\t\\r\\nPolydipsia 1.Yes, 2.No.\\t\\t\\r\\nsudden weight loss 1.Yes, 2.No.\\t\\t\\r\\nweakness 1.Yes, 2.No.\\t\\t\\r\\nPolyphagia 1.Yes, 2.No.\\t\\t\\r\\nGenital thrush 1.Yes, 2.No.\\t\\t\\r\\nvisual blurring 1.Yes, 2.No.\\t\\t\\r\\nItching 1.Yes, 2.No.\\t\\t\\r\\nIrritability 1.Yes, 2.No.\\t\\t\\r\\ndelayed healing 1.Yes, 2.No.\\t\\t\\r\\npartial paresis 1.Yes, 2.No.\\t\\t\\r\\nmuscle sti\\x0bness 1.Yes, 2.No.\\t\\t\\r\\nAlopecia 1.Yes, 2.No.\\t\\t\\r\\nObesity 1.Yes, 2.No.\\t\\t\\r\\nClass 1.Positive, 2.Negative.\\t\\t\\r\\n', 'citation': None}}\n",
      "                  name     role         type demographic description units  \\\n",
      "0                  age  Feature      Integer         Age        None  None   \n",
      "1               gender  Feature  Categorical      Gender        None  None   \n",
      "2             polyuria  Feature       Binary        None        None  None   \n",
      "3           polydipsia  Feature       Binary        None        None  None   \n",
      "4   sudden_weight_loss  Feature       Binary        None        None  None   \n",
      "5             weakness  Feature       Binary        None        None  None   \n",
      "6           polyphagia  Feature       Binary        None        None  None   \n",
      "7       genital_thrush  Feature       Binary        None        None  None   \n",
      "8      visual_blurring  Feature       Binary        None        None  None   \n",
      "9              itching  Feature       Binary        None        None  None   \n",
      "10        irritability  Feature       Binary        None        None  None   \n",
      "11     delayed_healing  Feature       Binary        None        None  None   \n",
      "12     partial_paresis  Feature       Binary        None        None  None   \n",
      "13    muscle_stiffness  Feature       Binary        None        None  None   \n",
      "14            alopecia  Feature       Binary        None        None  None   \n",
      "15             obesity  Feature       Binary        None        None  None   \n",
      "16               class   Target       Binary        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "early_stage_diabetes_risk_prediction = fetch_ucirepo(id=529) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = early_stage_diabetes_risk_prediction.data.features \n",
    "y = early_stage_diabetes_risk_prediction.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(early_stage_diabetes_risk_prediction.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(early_stage_diabetes_risk_prediction.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568e8e8a-af7c-4d0a-834d-0ad108f456b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV created: uci_scraped_links.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# 1. FIXED URL (Removed double https)\n",
    "url = \"https://archive.ics.uci.edu/datasets?search=heart+disease\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "try:\n",
    "    # 2. Added 10-second timeout\n",
    "    response = requests.get(url, headers=headers, timeout=10)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 3. Updated tags for the new UCI layout\n",
    "    dataset_list = []\n",
    "    # UCI now uses <a> tags with specific classes for dataset names\n",
    "    links = soup.find_all('a', class_='link-hover link-primary')\n",
    "    \n",
    "    for link in links[:10]:\n",
    "        title = link.get_text().strip()\n",
    "        href = \"https://archive.ics.uci.edu\" + link['href']\n",
    "        dataset_list.append({\"Dataset Name\": title, \"Link\": href})\n",
    "        print(f\"Found: {title} -> {href}\")\n",
    "\n",
    "    # 4. Save for Round 1 submission\n",
    "    df = pd.DataFrame(dataset_list)\n",
    "    df.to_csv(\"uci_scraped_links.csv\", index=False)\n",
    "    print(\"\\nCSV created: uci_scraped_links.csv\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Network error: {e}. Check your connection or try a different URL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114f0e4-3103-4889-b9ad-a5bd94543b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
